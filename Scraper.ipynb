{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9e7f24-92fd-40e7-bb2b-a23e6323e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190afcd-b403-4ec9-9bfc-761f0894bd10",
   "metadata": {},
   "source": [
    "# Scraping cars data from Avito.ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae138c4-b5eb-419b-9388-892e896ca606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start scraping\n",
      "Page 501 done: 35 cars found.\n",
      "Page 502 done: 35 cars found.\n",
      "Page 503 done: 35 cars found.\n",
      "Page 504 done: 35 cars found.\n",
      "Page 505 done: 35 cars found.\n",
      "Page 506 done: 35 cars found.\n",
      "Page 507 done: 35 cars found.\n",
      "Page 508 done: 35 cars found.\n",
      "Page 509 done: 35 cars found.\n",
      "Page 510 done: 35 cars found.\n",
      "Page 511 done: 35 cars found.\n",
      "Page 512 done: 35 cars found.\n",
      "Page 513 done: 35 cars found.\n",
      "Page 514 done: 35 cars found.\n",
      "Page 515 done: 35 cars found.\n",
      "Page 516 done: 35 cars found.\n",
      "Page 517 done: 35 cars found.\n",
      "Page 518 done: 35 cars found.\n",
      "Page 519 done: 35 cars found.\n",
      "Page 520 done: 35 cars found.\n",
      "Page 521 done: 35 cars found.\n",
      "Page 522 done: 35 cars found.\n",
      "Page 523 done: 35 cars found.\n",
      "Page 524 done: 35 cars found.\n",
      "Page 525 done: 35 cars found.\n",
      "Page 526 done: 35 cars found.\n",
      "Page 527 done: 35 cars found.\n",
      "Page 528 done: 35 cars found.\n",
      "Page 529 done: 35 cars found.\n",
      "Page 530 done: 35 cars found.\n",
      "Page 531 done: 35 cars found.\n",
      "Page 532 done: 35 cars found.\n",
      "Page 533 done: 35 cars found.\n",
      "Page 534 done: 35 cars found.\n",
      "Page 535 done: 35 cars found.\n",
      "Page 536 done: 35 cars found.\n",
      "Page 537 done: 35 cars found.\n",
      "Page 538 done: 35 cars found.\n",
      "Page 539 done: 35 cars found.\n",
      "Page 540 done: 35 cars found.\n",
      "Page 541 done: 35 cars found.\n",
      "Page 542 done: 35 cars found.\n",
      "Page 543 done: 35 cars found.\n",
      "Page 544 done: 35 cars found.\n",
      "Page 545 done: 35 cars found.\n",
      "Page 546 done: 35 cars found.\n",
      "Page 547 done: 35 cars found.\n",
      "Page 548 done: 35 cars found.\n",
      "Page 549 done: 35 cars found.\n",
      "Page 550 done: 35 cars found.\n",
      "Page 551 done: 35 cars found.\n",
      "Page 552 done: 35 cars found.\n",
      "Page 553 done: 35 cars found.\n",
      "Page 554 done: 35 cars found.\n",
      "Page 555 done: 35 cars found.\n",
      "Page 556 done: 35 cars found.\n",
      "Page 557 done: 35 cars found.\n",
      "Page 558 done: 35 cars found.\n",
      "Page 559 done: 35 cars found.\n",
      "Page 560 done: 35 cars found.\n",
      "Page 561 done: 35 cars found.\n",
      "Page 562 done: 35 cars found.\n",
      "Page 563 done: 35 cars found.\n",
      "Page 564 done: 35 cars found.\n",
      "Page 565 done: 35 cars found.\n",
      "Page 566 done: 35 cars found.\n",
      "Page 567 done: 35 cars found.\n",
      "Page 568 done: 35 cars found.\n",
      "Page 569 done: 35 cars found.\n",
      "Page 570 done: 35 cars found.\n",
      "Page 571 done: 35 cars found.\n",
      "Page 572 done: 35 cars found.\n",
      "Page 573 done: 35 cars found.\n",
      "Page 574 done: 35 cars found.\n",
      "Page 575 done: 35 cars found.\n",
      "Page 576 done: 35 cars found.\n",
      "Page 577 done: 35 cars found.\n",
      "Page 578 done: 35 cars found.\n",
      "Page 579 done: 35 cars found.\n",
      "Page 580 done: 35 cars found.\n",
      "Page 581 done: 35 cars found.\n",
      "Page 582 done: 35 cars found.\n",
      "Page 583 done: 35 cars found.\n",
      "Page 584 done: 35 cars found.\n",
      "Page 585 done: 35 cars found.\n",
      "Page 586 done: 35 cars found.\n",
      "Page 587 done: 35 cars found.\n",
      "Page 588 done: 35 cars found.\n",
      "Page 589 done: 35 cars found.\n",
      "Page 590 done: 35 cars found.\n",
      "Page 591 done: 35 cars found.\n",
      "Page 592 done: 35 cars found.\n",
      "Page 593 done: 35 cars found.\n",
      "Page 594 done: 35 cars found.\n",
      "Page 595 done: 35 cars found.\n",
      "Page 596 done: 35 cars found.\n",
      "Page 597 done: 35 cars found.\n",
      "Page 598 done: 35 cars found.\n",
      "Page 599 done: 35 cars found.\n",
      "Page 600 done: 35 cars found.\n",
      "Saved 20747 cars to Excel!\n",
      "Rows with bad characters: Empty DataFrame\n",
      "Columns: [id, list_id, title, description, price, old_price, location, ad_type, category, phone, seller_name, seller_type, seller_verified, type, sector, mileage, brand, model, doors, origin, first_owner, fiscal_power, condition, year, gearbox, fuel_type, abs, airbags, audio_system, rear_camera, ac, esp, alloy_wheels, speed_limiter, onboard_computer, rear_radar, cruise_control, leather_seats, navigation, sunroof, central_locking, electric_windows]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BASE_URL = \"https://www.avito.ma\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def clean_string(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Remove XML-invalid characters\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F-\\x9F\\uD800-\\uDFFF\\uFFFE\\uFFFF]', '', text)\n",
    "    text = text.replace('\\ufffd', ' ').strip()\n",
    "    text = ''.join(c for c in text if ord(c) <= 0xFFFF)\n",
    "    return text\n",
    "\n",
    "def clean_car_data(car_info):\n",
    "    cleaned = {}\n",
    "    for key, value in car_info.items():\n",
    "        if isinstance(value, str):\n",
    "            cleaned[key] = clean_string(value)\n",
    "        elif isinstance(value, dict):\n",
    "            cleaned[key] = clean_car_data(value)\n",
    "        elif isinstance(value, list):\n",
    "            cleaned[key] = [clean_string(item) if isinstance(item, str) else item for item in value]\n",
    "        else:\n",
    "            cleaned[key] = value\n",
    "    return cleaned\n",
    "\n",
    "def scrape_cars(start_page=1, end_page=1):\n",
    "    print(\"start scraping\")\n",
    "    all_cars = []\n",
    "\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        url = f\"{BASE_URL}/fr/maroc/voiture?o={page}\" if page > 1 else f\"{BASE_URL}/fr/maroc/voiture\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=HEADERS)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            script = soup.find('script', id='__NEXT_DATA__')\n",
    "\n",
    "            if not script:\n",
    "                print(f\"No script tag found on page {page}\")\n",
    "                continue\n",
    "\n",
    "            data = json.loads(script.string)\n",
    "            cars_url = data[\"props\"][\"pageProps\"][\"initialReduxState\"][\"ad\"][\"search\"][\"ads\"]\n",
    "\n",
    "            for car in cars_url:\n",
    "                car_url = urljoin(BASE_URL, car.get(\"href\", \"\")) if car.get(\"href\") else None\n",
    "                if not car_url:\n",
    "                    print(f\"No car URL found.\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    car_response = requests.get(car_url, headers=HEADERS)\n",
    "                    car_response.raise_for_status()\n",
    "                    car_soup = BeautifulSoup(car_response.text, 'html.parser')\n",
    "                    car_script = car_soup.find('script', id='__NEXT_DATA__')\n",
    "\n",
    "                    if not car_script:\n",
    "                        print(f\"No data found for car at {car_url}\")\n",
    "                        continue\n",
    "\n",
    "                    car_data_script = json.loads(car_script.string)\n",
    "                    car_data = car_data_script[\"props\"][\"pageProps\"][\"initialReduxState\"][\"ad\"][\"view\"][\"adInfo\"]\n",
    "\n",
    "                    params = car_data.get(\"params\", {})\n",
    "                    \n",
    "                    primary_params = {}\n",
    "                    for item in params.get(\"primary\", []):\n",
    "                        key = clean_string(item.get(\"key\")) if item.get(\"key\") else \"null\"\n",
    "                        value = clean_string(item.get(\"value\")) if item.get(\"value\") else \"null\"\n",
    "                        primary_params[key] = value\n",
    "                    \n",
    "                    secondary_params = {}\n",
    "                    for item in params.get(\"secondary\", []):\n",
    "                        key = clean_string(item.get(\"key\")) if item.get(\"key\") else \"null\"\n",
    "                        value = clean_string(item.get(\"value\")) if item.get(\"value\") else \"null\"\n",
    "                        secondary_params[key] = value\n",
    "                    \n",
    "                    extra_params = {}\n",
    "                    for item in params.get(\"extra\", []):\n",
    "                        key = clean_string(item.get(\"key\")) if item.get(\"key\") else \"null\"\n",
    "                        value = clean_string(item.get(\"value\")) if item.get(\"value\") else \"null\"\n",
    "                        extra_params[key] = value\n",
    "                    \n",
    "                    car_info = {\n",
    "                        \"id\": clean_string(str(car_data.get(\"id\", \"null\"))),\n",
    "                        \"list_id\": clean_string(str(car_data.get(\"listId\", \"null\"))),\n",
    "                        \"title\": clean_string(car_data.get(\"subject\", \"null\")),\n",
    "                        \"description\": clean_string(car_data.get(\"description\", \"null\")),\n",
    "                        \"price\": clean_string(str(car_data.get(\"price\", {}).get(\"value\", \"null\"))),\n",
    "                        \"old_price\": clean_string(str(car_data.get(\"old_price\", {}).get(\"value\", \"null\"))),\n",
    "                        \"location\": clean_string(car_data.get(\"location\", {}).get(\"city\", {}).get(\"name\", \"null\")),\n",
    "                        \"ad_type\": clean_string(car_data.get(\"type\", {}).get(\"label\", \"null\")),\n",
    "                        \"category\": clean_string(car_data.get(\"category\", {}).get(\"name\", \"null\")),\n",
    "                        \"phone\": clean_string(str(car_data.get(\"phone\", \"null\"))),\n",
    "                        \"seller_name\": clean_string(car_data.get(\"seller\", {}).get(\"name\", \"null\")),\n",
    "                        \"seller_type\": clean_string(car_data.get(\"seller\", {}).get(\"type\", \"null\")),\n",
    "                        \"seller_verified\": car_data.get(\"seller\", {}).get(\"isVerifiedSeller\", False),\n",
    "\n",
    "                        \"type\": clean_string(primary_params.get(\"SELL\", \"null\")),\n",
    "                        \"sector\": clean_string(primary_params.get(\"205\", \"null\")),\n",
    "                        \"mileage\": clean_string(primary_params.get(\"mileage\", \"null\")),\n",
    "                        \"brand\": clean_string(primary_params.get(\"brand\", \"null\")),\n",
    "                        \"model\": clean_string(primary_params.get(\"model\", \"null\")),\n",
    "                        \"doors\": clean_string(primary_params.get(\"doors\", \"null\")),\n",
    "                        \"origin\": clean_string(primary_params.get(\"v_origin\", \"null\")),\n",
    "                        \"first_owner\": clean_string(primary_params.get(\"first_owner\", \"null\")),\n",
    "                        \"fiscal_power\": clean_string(primary_params.get(\"pfiscale\", \"null\")),\n",
    "                        \"condition\": clean_string(primary_params.get(\"auto_condition\", \"null\")),\n",
    "\n",
    "                        \"year\": clean_string(secondary_params.get(\"regdate\", \"null\")),\n",
    "                        \"gearbox\": clean_string(secondary_params.get(\"bv\", \"null\")),\n",
    "                        \"fuel_type\": clean_string(secondary_params.get(\"fuel\", \"null\")),\n",
    "\n",
    "                        \"abs\": clean_string(extra_params.get(\"car_abs\", \"null\")),\n",
    "                        \"airbags\": clean_string(extra_params.get(\"car_airbags\", \"null\")),\n",
    "                        \"audio_system\": clean_string(extra_params.get(\"cd_mp3_bt\", \"null\")),\n",
    "                        \"rear_camera\": clean_string(extra_params.get(\"car_reverse_camera\", \"null\")),\n",
    "                        \"ac\": clean_string(extra_params.get(\"car_ac\", \"null\")),\n",
    "                        \"esp\": clean_string(extra_params.get(\"car_esp\", \"null\")),\n",
    "                        \"alloy_wheels\": clean_string(extra_params.get(\"car_rims\", \"null\")),\n",
    "                        \"speed_limiter\": clean_string(extra_params.get(\"car_speed_limiter\", \"null\")),\n",
    "                        \"onboard_computer\": clean_string(extra_params.get(\"car_onboard_computer\", \"null\")),\n",
    "                        \"rear_radar\": clean_string(extra_params.get(\"car_reverse_radar\", \"null\")),\n",
    "                        \"cruise_control\": clean_string(extra_params.get(\"car_cruise_control\", \"null\")),\n",
    "                        \"leather_seats\": clean_string(extra_params.get(\"car_leather\", \"null\")),\n",
    "                        \"navigation\": clean_string(extra_params.get(\"car_navigation\", \"null\")),\n",
    "                        \"sunroof\": clean_string(extra_params.get(\"car_roof\", \"null\")),\n",
    "                        \"central_locking\": clean_string(extra_params.get(\"car_central_locking\", \"null\")),\n",
    "                        \"electric_windows\": clean_string(extra_params.get(\"car_electric_windows\", \"null\"))\n",
    "                    }\n",
    "\n",
    "                    all_cars.append(car_info)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing car at {car_url}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "            print(f\"Page {page} done: {len(cars_url)} cars found.\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on page {page}: {str(e)}\")\n",
    "\n",
    "    return all_cars\n",
    "\n",
    "# Run scraper\n",
    "cars_data = scrape_cars(start_page=1, end_page=600)\n",
    "\n",
    "# Save to Excel\n",
    "output_file = \"avito_cars.xlsx\"\n",
    "\n",
    "try:\n",
    "    if os.path.exists(output_file):\n",
    "        existing_data = pd.read_excel(output_file)\n",
    "        all_data = pd.concat([existing_data, pd.DataFrame(cars_data)], ignore_index=True)\n",
    "    else:\n",
    "        all_data = pd.DataFrame(cars_data)\n",
    "\n",
    "    # Clean all string fields in one pass\n",
    "    for column in all_data.select_dtypes(include='object').columns:\n",
    "        all_data[column] = all_data[column].apply(lambda x: clean_string(str(x)) if pd.notnull(x) else x)\n",
    "\n",
    "    # Optionally remove duplicates\n",
    "    all_data.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "\n",
    "    all_data.to_excel(output_file, index=False)\n",
    "    print(f\"Saved {len(all_data)} cars to Excel!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saving to Excel: {str(e)}\")\n",
    "\n",
    "# Detect rows with invalid characters (optional)\n",
    "def find_invalid_excel_chars(s):\n",
    "    if not isinstance(s, str):\n",
    "        return False\n",
    "    return bool(re.search(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\uD800-\\uDFFF\\uFFFE\\uFFFF]', s))\n",
    "\n",
    "bad_rows = all_data.map(find_invalid_excel_chars).any(axis=1)\n",
    "print(\"Rows with bad characters:\", all_data[bad_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ad666-fd6b-41f1-8922-aef33f02d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
